

# INTRODUCTION

Use google BERT to do Chinese short text multi-class classification !

# RUN

- You need to download the trained model which is named *pytorch_model.bin* [here](https://drive.google.com/file/d/1Qcy7G4OyfC7ZvNtzoVLee4BsMjJa2FQz/view?usp=sharing) and put it in *chinese_L-12_H-768_A-12/* file.
- Files in the path *data/* are samples from our entire datasets 

# ACKNOWLEDGE

- [nlptown/**nlp-notebooks**](https://github.com/nlptown/nlp-notebooks)
- [huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT)
